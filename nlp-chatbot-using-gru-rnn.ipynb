{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nfrom sklearn import model_selection\nimport re","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:20.531582Z","iopub.execute_input":"2023-09-23T09:28:20.532134Z","iopub.status.idle":"2023-09-23T09:28:32.327848Z","shell.execute_reply.started":"2023-09-23T09:28:20.532091Z","shell.execute_reply":"2023-09-23T09:28:32.326450Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"data_df= pd.read_csv('/kaggle/input/cleaned-data-for-the-chatbot-collected-from-movies/dialogs_expanded.csv', index_col=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:32.330693Z","iopub.execute_input":"2023-09-23T09:28:32.331878Z","iopub.status.idle":"2023-09-23T09:28:33.903574Z","shell.execute_reply.started":"2023-09-23T09:28:32.331837Z","shell.execute_reply":"2023-09-23T09:28:33.902546Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:33.905200Z","iopub.execute_input":"2023-09-23T09:28:33.905560Z","iopub.status.idle":"2023-09-23T09:28:33.933833Z","shell.execute_reply.started":"2023-09-23T09:28:33.905524Z","shell.execute_reply":"2023-09-23T09:28:33.932900Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"        Unnamed: 0                                           question  \\\n0                1  Well, I thought we'd start with pronunciation,...   \n1                2  Not the hacking and gagging and spitting part....   \n2                3  You're asking me out.  That's so cute. What's ...   \n3                4  No, no, it's my fault -- we didn't have a prop...   \n4                9     Gosh, if only we could find Kat a boyfriend...   \n...            ...                                                ...   \n139404      221608    Well that one. The one who keeps looking at me.   \n139405      221609  Choose your targets men. That's right Watch th...   \n139406      221610  Colonel Durnford... William Vereker. I hear yo...   \n139407      221611                           Your orders, Mr Vereker?   \n139408      221612  I'm to take the Sikali with the main column to...   \n\n                                                   answer  \\\n0       Not the hacking and gagging and spitting part....   \n1       Okay... then how 'bout we try out some French ...   \n2                                              Forget it.   \n3                                                Cameron.   \n4                               Let me see what I can do.   \n...                                                   ...   \n139404  ft could be you flatter yourself CoghilL It's ...   \n139405  Keep steady. You're the best shots of the Twen...   \n139406  Good ones, yes, Mr Vereker. Gentlemen who can ...   \n139407  I'm to take the Sikali with the main column to...   \n139408  Lord Chelmsford seems to want me to stay back ...   \n\n                                          question_as_int  \\\n0       [54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...   \n1       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...   \n2       [56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...   \n3       [45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...   \n4       [38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...   \n...                                                   ...   \n139404  [54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...   \n139405  [34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...   \n139406  [34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...   \n139407  [56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...   \n139408  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...   \n\n                                            answer_as_int  question_len  \\\n0       [45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...            71   \n1       [46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...            55   \n2                 [37, 77, 80, 69, 67, 82, 1, 71, 82, 14]            62   \n3                        [34, 63, 75, 67, 80, 77, 76, 14]            65   \n4       [43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...            46   \n...                                                   ...           ...   \n139404  [68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...            47   \n139405  [42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...            61   \n139406  [38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...            74   \n139407  [40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...            24   \n139408  [43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...            56   \n\n        answer_len  \n0               55  \n1               73  \n2               10  \n3                8  \n4               25  \n...            ...  \n139404          59  \n139405          85  \n139406          60  \n139407          56  \n139408          62  \n\n[139409 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>question</th>\n      <th>answer</th>\n      <th>question_as_int</th>\n      <th>answer_as_int</th>\n      <th>question_len</th>\n      <th>answer_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>[54, 67, 74, 74, 12, 1, 40, 1, 82, 70, 77, 83,...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>71</td>\n      <td>55</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n      <td>[45, 77, 82, 1, 82, 70, 67, 1, 70, 63, 65, 73,...</td>\n      <td>[46, 73, 63, 87, 14, 14, 14, 1, 82, 70, 67, 76...</td>\n      <td>55</td>\n      <td>73</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n      <td>[56, 77, 83, 8, 80, 67, 1, 63, 81, 73, 71, 76,...</td>\n      <td>[37, 77, 80, 69, 67, 82, 1, 71, 82, 14]</td>\n      <td>62</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n      <td>[45, 77, 12, 1, 76, 77, 12, 1, 71, 82, 8, 81, ...</td>\n      <td>[34, 63, 75, 67, 80, 77, 76, 14]</td>\n      <td>65</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n      <td>[38, 77, 81, 70, 12, 1, 71, 68, 1, 77, 76, 74,...</td>\n      <td>[43, 67, 82, 1, 75, 67, 1, 81, 67, 67, 1, 85, ...</td>\n      <td>46</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>221608</td>\n      <td>Well that one. The one who keeps looking at me.</td>\n      <td>ft could be you flatter yourself CoghilL It's ...</td>\n      <td>[54, 67, 74, 74, 1, 82, 70, 63, 82, 1, 77, 76,...</td>\n      <td>[68, 82, 1, 65, 77, 83, 74, 66, 1, 64, 67, 1, ...</td>\n      <td>47</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>221609</td>\n      <td>Choose your targets men. That's right Watch th...</td>\n      <td>Keep steady. You're the best shots of the Twen...</td>\n      <td>[34, 70, 77, 77, 81, 67, 1, 87, 77, 83, 80, 1,...</td>\n      <td>[42, 67, 67, 78, 1, 81, 82, 67, 63, 66, 87, 14...</td>\n      <td>61</td>\n      <td>85</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>221610</td>\n      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n      <td>[34, 77, 74, 77, 76, 67, 74, 1, 35, 83, 80, 76...</td>\n      <td>[38, 77, 77, 66, 1, 77, 76, 67, 81, 12, 1, 87,...</td>\n      <td>74</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>221611</td>\n      <td>Your orders, Mr Vereker?</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>[56, 77, 83, 80, 1, 77, 80, 66, 67, 80, 81, 12...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>24</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>221612</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>Lord Chelmsford seems to want me to stay back ...</td>\n      <td>[40, 8, 75, 1, 82, 77, 1, 82, 63, 73, 67, 1, 8...</td>\n      <td>[43, 77, 80, 66, 1, 34, 70, 67, 74, 75, 81, 68...</td>\n      <td>56</td>\n      <td>62</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.drop(['Unnamed: 0','question_as_int','answer_as_int','question_len','answer_len'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:33.936795Z","iopub.execute_input":"2023-09-23T09:28:33.937164Z","iopub.status.idle":"2023-09-23T09:28:33.964028Z","shell.execute_reply.started":"2023-09-23T09:28:33.937128Z","shell.execute_reply":"2023-09-23T09:28:33.962907Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_df.info()","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:33.965990Z","iopub.execute_input":"2023-09-23T09:28:33.966887Z","iopub.status.idle":"2023-09-23T09:28:34.062609Z","shell.execute_reply.started":"2023-09-23T09:28:33.966850Z","shell.execute_reply":"2023-09-23T09:28:34.061659Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 139409 entries, 0 to 139408\nData columns (total 2 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   question  139409 non-null  object\n 1   answer    139409 non-null  object\ndtypes: object(2)\nmemory usage: 2.1+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:34.064061Z","iopub.execute_input":"2023-09-23T09:28:34.064653Z","iopub.status.idle":"2023-09-23T09:28:34.078508Z","shell.execute_reply.started":"2023-09-23T09:28:34.064617Z","shell.execute_reply":"2023-09-23T09:28:34.077439Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n0       Well, I thought we'd start with pronunciation,...   \n1       Not the hacking and gagging and spitting part....   \n2       You're asking me out.  That's so cute. What's ...   \n3       No, no, it's my fault -- we didn't have a prop...   \n4          Gosh, if only we could find Kat a boyfriend...   \n...                                                   ...   \n139404    Well that one. The one who keeps looking at me.   \n139405  Choose your targets men. That's right Watch th...   \n139406  Colonel Durnford... William Vereker. I hear yo...   \n139407                           Your orders, Mr Vereker?   \n139408  I'm to take the Sikali with the main column to...   \n\n                                                   answer  \n0       Not the hacking and gagging and spitting part....  \n1       Okay... then how 'bout we try out some French ...  \n2                                              Forget it.  \n3                                                Cameron.  \n4                               Let me see what I can do.  \n...                                                   ...  \n139404  ft could be you flatter yourself CoghilL It's ...  \n139405  Keep steady. You're the best shots of the Twen...  \n139406  Good ones, yes, Mr Vereker. Gentlemen who can ...  \n139407  I'm to take the Sikali with the main column to...  \n139408  Lord Chelmsford seems to want me to stay back ...  \n\n[139409 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>Well that one. The one who keeps looking at me.</td>\n      <td>ft could be you flatter yourself CoghilL It's ...</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>Choose your targets men. That's right Watch th...</td>\n      <td>Keep steady. You're the best shots of the Twen...</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>Colonel Durnford... William Vereker. I hear yo...</td>\n      <td>Good ones, yes, Mr Vereker. Gentlemen who can ...</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>Your orders, Mr Vereker?</td>\n      <td>I'm to take the Sikali with the main column to...</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>I'm to take the Sikali with the main column to...</td>\n      <td>Lord Chelmsford seems to want me to stay back ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:34.080074Z","iopub.execute_input":"2023-09-23T09:28:34.080456Z","iopub.status.idle":"2023-09-23T09:28:34.090338Z","shell.execute_reply.started":"2023-09-23T09:28:34.080420Z","shell.execute_reply":"2023-09-23T09:28:34.089268Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                            question  \\\n0  Well, I thought we'd start with pronunciation,...   \n1  Not the hacking and gagging and spitting part....   \n2  You're asking me out.  That's so cute. What's ...   \n3  No, no, it's my fault -- we didn't have a prop...   \n4     Gosh, if only we could find Kat a boyfriend...   \n5                     C'esc ma tete. This is my head   \n6               That's because it's such a nice one.   \n7  How is our little Find the Wench A Date plan p...   \n8                  You have my word.  As a gentleman   \n9                                         Sure have.   \n\n                                              answer  \n0  Not the hacking and gagging and spitting part....  \n1  Okay... then how 'bout we try out some French ...  \n2                                         Forget it.  \n3                                           Cameron.  \n4                          Let me see what I can do.  \n5           Right.  See?  You're ready for the quiz.  \n6                                     Forget French.  \n7          Well, there's someone I think might be --  \n8                                      You're sweet.  \n9  I really, really, really wanna go, but I can't...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Well, I thought we'd start with pronunciation,...</td>\n      <td>Not the hacking and gagging and spitting part....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not the hacking and gagging and spitting part....</td>\n      <td>Okay... then how 'bout we try out some French ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>You're asking me out.  That's so cute. What's ...</td>\n      <td>Forget it.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No, no, it's my fault -- we didn't have a prop...</td>\n      <td>Cameron.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Gosh, if only we could find Kat a boyfriend...</td>\n      <td>Let me see what I can do.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>C'esc ma tete. This is my head</td>\n      <td>Right.  See?  You're ready for the quiz.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>That's because it's such a nice one.</td>\n      <td>Forget French.</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>How is our little Find the Wench A Date plan p...</td>\n      <td>Well, there's someone I think might be --</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>You have my word.  As a gentleman</td>\n      <td>You're sweet.</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sure have.</td>\n      <td>I really, really, really wanna go, but I can't...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:34.092017Z","iopub.execute_input":"2023-09-23T09:28:34.092786Z","iopub.status.idle":"2023-09-23T09:28:34.113243Z","shell.execute_reply.started":"2023-09-23T09:28:34.092673Z","shell.execute_reply":"2023-09-23T09:28:34.112131Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n99475                                Hi.  Is Frank there?   \n37183   That Foley looks like he's been through a war ...   \n136853                                  Why are you here?   \n29397                      You're not contagious are you?   \n70432                   ...to die for a country that's...   \n40594                     How long ago was your makeover?   \n84563                            Don't tell me I can't --   \n13092                   I don't know. I was just curious.   \n138232  I'm fine. I'm going to live a long time. That'...   \n24617                  That would be Beaumont Livingston.   \n\n                                    answer  \n99475   I think you have the wrong number.  \n37183                    I've seen better.  \n136853                       I don't know.  \n29397                    I don't think so.  \n70432       ...never done a thing for you?  \n40594                            My what?!  \n84563           They're trying to kill me!  \n13092                 Maybe yes. Maybe no.  \n138232                            Johnny   \n24617     That's him. How do you know 'em?  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>99475</th>\n      <td>Hi.  Is Frank there?</td>\n      <td>I think you have the wrong number.</td>\n    </tr>\n    <tr>\n      <th>37183</th>\n      <td>That Foley looks like he's been through a war ...</td>\n      <td>I've seen better.</td>\n    </tr>\n    <tr>\n      <th>136853</th>\n      <td>Why are you here?</td>\n      <td>I don't know.</td>\n    </tr>\n    <tr>\n      <th>29397</th>\n      <td>You're not contagious are you?</td>\n      <td>I don't think so.</td>\n    </tr>\n    <tr>\n      <th>70432</th>\n      <td>...to die for a country that's...</td>\n      <td>...never done a thing for you?</td>\n    </tr>\n    <tr>\n      <th>40594</th>\n      <td>How long ago was your makeover?</td>\n      <td>My what?!</td>\n    </tr>\n    <tr>\n      <th>84563</th>\n      <td>Don't tell me I can't --</td>\n      <td>They're trying to kill me!</td>\n    </tr>\n    <tr>\n      <th>13092</th>\n      <td>I don't know. I was just curious.</td>\n      <td>Maybe yes. Maybe no.</td>\n    </tr>\n    <tr>\n      <th>138232</th>\n      <td>I'm fine. I'm going to live a long time. That'...</td>\n      <td>Johnny </td>\n    </tr>\n    <tr>\n      <th>24617</th>\n      <td>That would be Beaumont Livingston.</td>\n      <td>That's him. How do you know 'em?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### re is a package to take care of regular expressions in the data\n##### re.sub is used to substitute the expression with given input","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n  text = text.lower()\n  text = re.sub('\\[.*?\\]', '', text)\n  text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n  text = re.sub('<.*?>+', '', text)\n  text = re.sub('\\n', '', text)\n  text = re.sub(r'[^\\w]',' ',text)\n  text = re.sub('\\w*\\d\\w*', '', text)\n  return text\n\ndata_df.question = data_df.question.map(clean_text)\ndata_df.answer = data_df.answer.map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:34.114864Z","iopub.execute_input":"2023-09-23T09:28:34.115322Z","iopub.status.idle":"2023-09-23T09:28:40.436804Z","shell.execute_reply.started":"2023-09-23T09:28:34.115275Z","shell.execute_reply":"2023-09-23T09:28:40.435788Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def add_start_end(text):\n  text = f'<start> {text} <end>'\n  return text\n\ndata_df.question = data_df.question.map(add_start_end)\ndata_df.answer = data_df.answer.map(add_start_end)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:40.442342Z","iopub.execute_input":"2023-09-23T09:28:40.442719Z","iopub.status.idle":"2023-09-23T09:28:40.584824Z","shell.execute_reply.started":"2023-09-23T09:28:40.442689Z","shell.execute_reply":"2023-09-23T09:28:40.583774Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_df","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:40.586299Z","iopub.execute_input":"2023-09-23T09:28:40.586910Z","iopub.status.idle":"2023-09-23T09:28:40.603924Z","shell.execute_reply.started":"2023-09-23T09:28:40.586871Z","shell.execute_reply":"2023-09-23T09:28:40.602513Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                                 question  \\\n0       <start> well  i thought we d start with pronun...   \n1       <start> not the hacking and gagging and spitti...   \n2       <start> you re asking me out   that s so cute ...   \n3       <start> no  no  it s my fault    we didn t hav...   \n4       <start> gosh  if only we could find kat a boyf...   \n...                                                   ...   \n139404  <start> well that one  the one who keeps looki...   \n139405  <start> choose your targets men  that s right ...   \n139406  <start> colonel durnford    william vereker  i...   \n139407             <start> your orders  mr vereker  <end>   \n139408  <start> i m to take the sikali with the main c...   \n\n                                                   answer  \n0       <start> not the hacking and gagging and spitti...  \n1       <start> okay    then how  bout we try out some...  \n2                                <start> forget it  <end>  \n3                                  <start> cameron  <end>  \n4                 <start> let me see what i can do  <end>  \n...                                                   ...  \n139404  <start> ft could be you flatter yourself coghi...  \n139405  <start> keep steady  you re the best shots of ...  \n139406  <start> good ones  yes  mr vereker  gentlemen ...  \n139407  <start> i m to take the sikali with the main c...  \n139408  <start> lord chelmsford seems to want me to st...  \n\n[139409 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; well  i thought we d start with pronun...</td>\n      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; not the hacking and gagging and spitti...</td>\n      <td>&lt;start&gt; okay    then how  bout we try out some...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; you re asking me out   that s so cute ...</td>\n      <td>&lt;start&gt; forget it  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; no  no  it s my fault    we didn t hav...</td>\n      <td>&lt;start&gt; cameron  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; gosh  if only we could find kat a boyf...</td>\n      <td>&lt;start&gt; let me see what i can do  &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>139404</th>\n      <td>&lt;start&gt; well that one  the one who keeps looki...</td>\n      <td>&lt;start&gt; ft could be you flatter yourself coghi...</td>\n    </tr>\n    <tr>\n      <th>139405</th>\n      <td>&lt;start&gt; choose your targets men  that s right ...</td>\n      <td>&lt;start&gt; keep steady  you re the best shots of ...</td>\n    </tr>\n    <tr>\n      <th>139406</th>\n      <td>&lt;start&gt; colonel durnford    william vereker  i...</td>\n      <td>&lt;start&gt; good ones  yes  mr vereker  gentlemen ...</td>\n    </tr>\n    <tr>\n      <th>139407</th>\n      <td>&lt;start&gt; your orders  mr vereker  &lt;end&gt;</td>\n      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n    </tr>\n    <tr>\n      <th>139408</th>\n      <td>&lt;start&gt; i m to take the sikali with the main c...</td>\n      <td>&lt;start&gt; lord chelmsford seems to want me to st...</td>\n    </tr>\n  </tbody>\n</table>\n<p>139409 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"#### Tokenizer is used for text pre processing\n##### filters describe all the characters which are to be removed\n##### oov_token is used for out of vocab words to be replaced by 'OOV'","metadata":{}},{"cell_type":"markdown","source":"##### After making seperate tokens we convert words into integer values using texts_to_sequence\n##### pad_sequence is used to add padding to sequence to make them all same length","metadata":{}},{"cell_type":"code","source":"def tokenize(lang):\n  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n      filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n', oov_token='<OOV>'\n  )\n  lang_tokenizer.fit_on_texts(lang)\n  tensor = lang_tokenizer.texts_to_sequences(lang)\n  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n  return tensor, lang_tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:40.605468Z","iopub.execute_input":"2023-09-23T09:28:40.605858Z","iopub.status.idle":"2023-09-23T09:28:40.614468Z","shell.execute_reply.started":"2023-09-23T09:28:40.605819Z","shell.execute_reply":"2023-09-23T09:28:40.613231Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"question_sequence, question_tokenizer = tokenize(data_df.question)\nanswer_sequence, answer_tokenizer = tokenize(data_df.answer)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:40.616184Z","iopub.execute_input":"2023-09-23T09:28:40.616695Z","iopub.status.idle":"2023-09-23T09:28:51.035931Z","shell.execute_reply.started":"2023-09-23T09:28:40.616653Z","shell.execute_reply":"2023-09-23T09:28:51.034917Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting the data into training and test data","metadata":{}},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = model_selection.train_test_split(question_sequence, \n                answer_sequence, test_size = 0.1, random_state=42) \n\nx_train.shape, x_test.shape, y_train.shape, y_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:51.037570Z","iopub.execute_input":"2023-09-23T09:28:51.037981Z","iopub.status.idle":"2023-09-23T09:28:51.084694Z","shell.execute_reply.started":"2023-09-23T09:28:51.037942Z","shell.execute_reply":"2023-09-23T09:28:51.083781Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"((125468, 29), (13941, 29), (125468, 32), (13941, 32))"},"metadata":{}}]},{"cell_type":"markdown","source":"##### For each element t in the tensor, it checks if t is not equal to 0 (assuming 0 is used as a padding token or a special token). If t is not 0, it prints the integer t and its corresponding word in the tokenizer's vocabulary using lang.index_word[t].\n","metadata":{}},{"cell_type":"code","source":"def convert(lang, tensor):\n  for t in tensor:\n    if t!=0:\n      print('%d---> %s' % (t, lang.index_word[t]))\n\nprint('Question')\nconvert(question_tokenizer, x_train[0])\nprint()\nprint('Answer')\nconvert(answer_tokenizer, y_train[0])","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:51.086340Z","iopub.execute_input":"2023-09-23T09:28:51.086692Z","iopub.status.idle":"2023-09-23T09:28:51.097113Z","shell.execute_reply.started":"2023-09-23T09:28:51.086659Z","shell.execute_reply":"2023-09-23T09:28:51.092915Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Question\n2---> <start>\n80---> yeah\n13---> that\n8---> s\n11002---> blush\n36---> on\n32---> my\n301---> wife\n3384---> uses\n9---> it\n3---> <end>\n\nAnswer\n2---> <start>\n204---> ask\n5535---> travis\n22---> he\n7---> s\n6---> the\n1765---> ladies\n104---> man\n3---> <end>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### #vocab input size takes the size of input values\n##### #tar size takes the size of target values\n##### #embedding dimensionality specifies how many dimensions each word embedding vector will have\n##### #units  specifies the number of units (neurons) in the recurrent layers of the sequence-to-sequence model\n##### #batch size  refers to the number of input sequences processed together during training","metadata":{}},{"cell_type":"code","source":"vocab_inp_size = len(question_tokenizer.word_index)+1\nvocab_tar_size =  len(answer_tokenizer.word_index)+1\nembedding_dim = 256\nunits = 1024\nbatch_size=32","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:51.099164Z","iopub.execute_input":"2023-09-23T09:28:51.099811Z","iopub.status.idle":"2023-09-23T09:28:51.107113Z","shell.execute_reply.started":"2023-09-23T09:28:51.099771Z","shell.execute_reply":"2023-09-23T09:28:51.106037Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"##### The following code creates train dataset and test dataset containing a pair from x and y\n##### to randomize the data shuffle is used and the batches of 32 each are prepared to be processed together\n##### prefetch allows tensorflow to pick the number of batches to be processed at a time according to the resources","metadata":{}},{"cell_type":"code","source":"def create_dataset(x, y, batch_size=32):\n  data = tf.data.Dataset.from_tensor_slices((x, y))\n\n  data = data.shuffle(1028)\n  data = data.batch(batch_size, drop_remainder=True)\n\n  data = data.prefetch(tf.data.experimental.AUTOTUNE)\n\n  return data\n\ntrain_dataset = create_dataset(x_train, y_train)\ntest_dataset = create_dataset(x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:51.108895Z","iopub.execute_input":"2023-09-23T09:28:51.109278Z","iopub.status.idle":"2023-09-23T09:28:55.468212Z","shell.execute_reply.started":"2023-09-23T09:28:51.109229Z","shell.execute_reply":"2023-09-23T09:28:55.467072Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"  for q, a in train_dataset.take(1):\n    print(f'Question:{q.shape}\\n{q}')\n  \n    print(f'Answer:{a.shape}\\n{a}')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:55.471990Z","iopub.execute_input":"2023-09-23T09:28:55.472657Z","iopub.status.idle":"2023-09-23T09:28:55.568672Z","shell.execute_reply.started":"2023-09-23T09:28:55.472620Z","shell.execute_reply":"2023-09-23T09:28:55.567459Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Question:(32, 29)\n[[    2   629    60    10  1922    67   417    14    24    15    32   493\n   3534     3     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   364    30   776     3     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    33   167     4     3     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    16    55     5    56     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   159    16    10   155     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    18  1070     9     8     6  2026     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    58    17   972   102    43   158    11    28    10   461    49\n     17   223    45     7     6  1882     3     0     0     0     0     0\n      0     0     0     0     0]\n [    2    67    33    33     5    56    17    25   448   120   107  5455\n     27    99    42    13     3     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    69  2264     5    21    11    26     4     3     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2  1643   156     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    58     4   204    14     6  2124    57    12    22  4516     5\n     23   506    22     8   212     3     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   181   130    94     9     8    39    10   930     3     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     4    93  8450     5   219    11   503    19    13  9994     7\n    930    53    33  1795     3     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    39   189     9    19    32   262     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    49     5    39  2156    10   779  2510     5    34    59   698\n      5    52     7     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    88    69    55     5    56    22     8  1067     3     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    38   120     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    80    62    67   254   253     5    63    57     7    59   167\n      4   179  3516     3     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   376     5    35   250    32   323     8    10  4011  2859     3\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   115  2715    20     4   213    14     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     5  1999    60    10   122     5    23   344    27    10   206\n     13     8  1421   180 26554     3     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2   133     4    39    57    10   250   443  1110  1319    45    10\n    230    16    30   294     3     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2  8364     3     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     4    25   311  1240  6851 14603   300     3     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     4    82    19     6   511     3     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    49    85  1617  8491     6  6379    16   142  8492     3     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    67   145     9    35   150   131   143   106   148   317    22\n    237    14    88    42    92  1429     3     0     0     0     0     0\n      0     0     0     0     0]\n [    2   322     7    54     9   209   903     3     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     4   431     5    54     3     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2  3997     6   270     8    10  1934 25001  1934  1726     3     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2    38    76   335    90     8     4   152    44     3     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]\n [    2     9     8   779     3     0     0     0     0     0     0     0\n      0     0     0     0     0     0     0     0     0     0     0     0\n      0     0     0     0     0]]\nAnswer:(32, 32)\n[[   2 1575    8 ...    0    0    0]\n [   2  335   32 ...    0    0    0]\n [   2  572   14 ...    0    0    0]\n ...\n [   2    4  389 ...    0    0    0]\n [   2  402   16 ...    0    0    0]\n [   2    5   27 ...    0    0    0]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### The encoder is responsible for processing the input sequence and producing an encoding or hidden state that contains information about the input sequence.\n##### embedding converts the input integers into dense vectors and masks the padding used \n##### A GRU (Gated Recurrent Unit) layer, which is a type of recurrent neural network (RNN) layer. It is configured to return both sequences and the final state of the encoder. The recurrent_initializer='glorot_uniform' parameter sets the initializer for the recurrent weights.\n","metadata":{}},{"cell_type":"code","source":"class Encoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, encoder_units, batch_size):\n      super(Encoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.encoder_units = encoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.encoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, state = self.gru(x, initial_state = hidden)\n    return output, state\n\n  def initialize_hidden_state(self):\n    return tf.zeros((self.batch_size, self.encoder_units))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:55.570581Z","iopub.execute_input":"2023-09-23T09:28:55.571370Z","iopub.status.idle":"2023-09-23T09:28:55.580884Z","shell.execute_reply.started":"2023-09-23T09:28:55.571327Z","shell.execute_reply":"2023-09-23T09:28:55.579620Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"##### The decoder is responsible for generating output sequences based on the encoded input information.\n##### It takes the hidden layer as input or to remember the initial state\n#### The decoder's output is compared to the target sequences to compute loss, and during inference, it generates sequences one step at a time based on previously generated tokens and the decoder's internal state.","metadata":{}},{"cell_type":"code","source":"class Decoder(tf.keras.Model):\n  def __init__(self, vocab_size, embedding_dim, decoder_units, batch_size):\n      super(Decoder, self).__init__()\n\n      self.batch_size = batch_size\n      self.decoder_units = decoder_units\n      self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n      self.gru = tf.keras.layers.GRU(self.decoder_units, \n                                           return_sequences=True,\n                                           return_state=True,\n                                           recurrent_initializer = 'glorot_uniform')\n      \n      self.fc = tf.keras.layers.Dense(vocab_size)\n\n\n  def call(self, x, hidden):\n    x = self.embedding(x)\n    output, hidden = self.gru(x, initial_state = hidden)\n    output = tf.reshape(output, (-1, output.shape[2]))\n    x =  tf.nn.softmax(self.fc(output))\n    return x, hidden","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:55.582441Z","iopub.execute_input":"2023-09-23T09:28:55.583653Z","iopub.status.idle":"2023-09-23T09:28:55.594592Z","shell.execute_reply.started":"2023-09-23T09:28:55.583611Z","shell.execute_reply":"2023-09-23T09:28:55.593516Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# vocab_inp_size = len(eng_tokenizer.word_index)+1\n# vocab_tar_size =  len(spn_tokenizer.word_index)+1\n# embedding_dim = 256\n# units = 1024\n# batch_size=32\n\nencoder = Encoder(vocab_inp_size, embedding_dim, units, batch_size)\nsample_hidden = encoder.initialize_hidden_state()\nsample_output, sample_hidden = encoder(q, sample_hidden)\nprint ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\nprint ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:55.596214Z","iopub.execute_input":"2023-09-23T09:28:55.596770Z","iopub.status.idle":"2023-09-23T09:28:59.247822Z","shell.execute_reply.started":"2023-09-23T09:28:55.596714Z","shell.execute_reply":"2023-09-23T09:28:59.246801Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Encoder output shape: (batch size, sequence length, units) (32, 29, 1024)\nEncoder Hidden state shape: (batch size, units) (32, 1024)\n","output_type":"stream"}]},{"cell_type":"code","source":"decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n\nsample_decoder_output, _ = decoder(tf.random.uniform((batch_size, 1)), sample_hidden)\n\nprint ('Decoder output shape: (batch size, vocab_size) {}'.format(sample_decoder_output.shape))","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.252216Z","iopub.execute_input":"2023-09-23T09:28:59.254964Z","iopub.status.idle":"2023-09-23T09:28:59.341477Z","shell.execute_reply.started":"2023-09-23T09:28:59.254919Z","shell.execute_reply":"2023-09-23T09:28:59.340499Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Decoder output shape: (batch size, vocab_size) (32, 27849)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### (tf.keras.optimizers.Adam()) is a popular optimization algorithm for training deep neural networks. The optimizer is used to update the model's weights during training, aiming to minimize the defined loss function.\n##### The loss function chosen here is SparseCategoricalCrossentropy, which is often used for tasks where each target sequence is a sequence of integers ","metadata":{}},{"cell_type":"markdown","source":"##### The loss_object is applied to compute the loss, and it results in a loss tensor of the same shape as the input.The loss tensor is element-wise multiplied by the mask, effectively zeroing out the loss contributions from padding tokens. Finally, it computes the mean loss across the batch dimension, which provides the average loss per batch while ignoring padding tokens.","metadata":{}},{"cell_type":"code","source":"# create the optimizer using the Adam optimizer\noptimizer = tf.keras.optimizers.Adam()\n# create the loss function\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n    from_logits=False, reduction='none')\n\n# define the loss function for the training\ndef loss_function(real, pred):\n  # create the mask to ignore the padding tokens\n  mask = tf.math.logical_not(tf.math.equal(real, 0))\n  # mask shape == (batch_size, sequence_length)\n  # calculate the loss\n  loss_ = loss_object(real, pred)\n  # mask the loss\n  # how the mask works:\n  # if the value is 1, the loss is calculated\n  # if the value is 0, the loss is ignored\n    #[1,1,1,1,1,1,0,0,0,0,0] mask\n    # *\n    #[2,6,2,1,6,3,2,1,5,7,9] input\n    # =\n    #[2,6,2,1,6,3,0,0,0,0,0] output\n  mask = tf.cast(mask, dtype=loss_.dtype)\n  # mask shape == (batch_size, sequence_length)\n\n  loss_ *= mask\n  # calculate the average loss per batch \n  return tf.reduce_mean(loss_)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.343789Z","iopub.execute_input":"2023-09-23T09:28:59.344446Z","iopub.status.idle":"2023-09-23T09:28:59.355630Z","shell.execute_reply.started":"2023-09-23T09:28:59.344408Z","shell.execute_reply":"2023-09-23T09:28:59.354559Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# create the training metric \ntrain_loss = tf.metrics.Mean(name='train loss')\n# create the testing metric \ntest_loss =tf.metrics.Mean(name='test loss')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.357527Z","iopub.execute_input":"2023-09-23T09:28:59.358229Z","iopub.status.idle":"2023-09-23T09:28:59.377203Z","shell.execute_reply.started":"2023-09-23T09:28:59.358194Z","shell.execute_reply":"2023-09-23T09:28:59.376048Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"####  training step is designed to be used within a training loop to update the model's weights based on a batch of training data.\n","metadata":{}},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function\n# define the training step \ndef train_step(inputs, target, enc_hidden):\n  # the encoder_hidden is the initial hidden state of the encoder\n  # enc_hidden shape == (batch_size, hidden_size)\n\n  # inilaize the loss to zero\n  loss = 0\n  # create the gradient tape to record the gradient of the loss with respect to the weights\n\n  with tf.GradientTape() as tape:\n    # pass the input to the encoder\n    # enc_output shape == (batch_size, 49, hidden_size)\n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    # using the encoder_hidden as the initial hidden state of the decoder\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n\n    # create the start token \n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    \n    # Teacher forcing - feeding the target as the next input\n    \n    for t in range(1, target.shape[1]):\n      # passing enc_output to the decoder\n      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n      # calculate the loss for the current time step using the loss function\n      loss += loss_function(target[:, t], predictions)\n\n      # using teacher forcing\n      dec_input = tf.expand_dims(target[:, t], 1)\n  # calculate the loss for the current batch\n  batch_loss = (loss / int(target.shape[1]))\n\n  # get the trainable variables\n  variables = encoder.trainable_variables + decoder.trainable_variables\n  # calculate the gradients using the tape \n  gradients = tape.gradient(loss, variables)\n  # update the trainable variables\n  optimizer.apply_gradients(zip(gradients, variables))\n  # add the loss to the training loss metric\n  train_loss(batch_loss)\n  return batch_loss","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.378900Z","iopub.execute_input":"2023-09-23T09:28:59.379774Z","iopub.status.idle":"2023-09-23T09:28:59.390175Z","shell.execute_reply.started":"2023-09-23T09:28:59.379713Z","shell.execute_reply":"2023-09-23T09:28:59.389258Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# create the training step\n# using the tf.function decorator to speed up the training process by converting the training function to a TensorFlow graph\n@tf.function \ndef test_step(inputs, target, enc_hidden):\n    # the encoder_hidden is the initial hidden state of the encoder\n    # enc_hidden shape == (batch_size, hidden_size)\n    # inilaize the loss to zero\n    loss = 0\n    # pass the input to the encoder \n    # enc_output shape == (batch_size, 49, hidden_size) \n    # enc_hidden shape == (batch_size, hidden_size)\n    # using the encoder to get the encoder_output and the encoder_hidden\n    enc_output, enc_hidden = encoder(inputs, enc_hidden)\n    # set the initial decoder hidden state to the encoder hidden state\n    dec_hidden = enc_hidden\n    # create the start token\n    # start_token shape == (batch_size, 1)\n    # repeat the start token for the batch size times\n    dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']] * inputs.shape[0], 1)\n    for t in range(1, target.shape[1]):\n        # passing enc_output to the decoder with dec_hidden as the initial hidden state\n        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n        # calculate the loss for the current time step using the loss function \n        loss += loss_function(target[:, t], predictions)\n\n        # using teacher forcing\n        dec_input = tf.expand_dims(target[:, t], 1)\n    # calculate the loss for the current batch\n    batch_loss = (loss / int(target.shape[1]))\n    # add the batch loss to the test loss metric\n    test_loss(batch_loss)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.391664Z","iopub.execute_input":"2023-09-23T09:28:59.392134Z","iopub.status.idle":"2023-09-23T09:28:59.407006Z","shell.execute_reply.started":"2023-09-23T09:28:59.392084Z","shell.execute_reply":"2023-09-23T09:28:59.405900Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# set the epochs to 10\nEPOCHS = 10\n# set the old test loss to high number \n\nold_test_loss=1000000\n# create the training loop\nfor epoch in range(EPOCHS):\n    # reset the training loss metric\n    train_loss.reset_states()\n    # reset the testing loss metric\n    test_loss.reset_states()\n\n    # initalize the hidden state of the encoder to zeros \n    enc_hidden = encoder.initialize_hidden_state()\n    # create the training progress bar set the total number of batches to the length of the training dataset and the batch size to the test size\n    steps_per_epoch = answer_sequence.shape[0]//batch_size #=> 4356 batch in the dataset \n    bar = tf.keras.utils.Progbar(target=steps_per_epoch)\n    \n    count=0\n    # iterate over the training dataset \n    for (batch, (inputs, target)) in enumerate(train_dataset):\n        # update the progress bar\n     count += 1\n        # run the training step\n     batch_loss = train_step(inputs, target, enc_hidden)\n     bar.update(count)  # manually update the progress bar\n                                                  \n    \n    \n    # iterate over the testing dataset    \n    for (batch, (inputs, target)) in enumerate(test_dataset):\n     count += 1\n        # run the testing step\n     batch_loss = test_step(inputs, target, enc_hidden)\n    bar.update(count)\n    # save the best performance model on the test dataset \n    \n    if old_test_loss> test_loss.result():\n        # set the old test loss to the test loss \n        old_test_loss= test_loss.result()\n        encoder.save(filepath='/content/models/encoder')\n        decoder.save(filepath='/content/models/decoder')\n        print('Model is saved')\n    # print the training and testing loss\n    print('#' * 50)\n    print(f'Epoch #{epoch + 1}')\n    print(f'Training Loss {train_loss.result()}')\n    print(f'Testing Loss {test_loss.result()}')\n    print('#' * 50)","metadata":{"execution":{"iopub.status.busy":"2023-09-23T09:28:59.408204Z","iopub.execute_input":"2023-09-23T09:28:59.408752Z","iopub.status.idle":"2023-09-23T12:01:14.754792Z","shell.execute_reply.started":"2023-09-23T09:28:59.408701Z","shell.execute_reply":"2023-09-23T12:01:14.753435Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"4355/4356 [============================>.] - ETA: 0s  Model is saved\n##################################################\nEpoch #1\nTraining Loss 1.4245524406433105\nTesting Loss 1.2976245880126953\n##################################################\n4355/4356 [============================>.] - ETA: 0s  Model is saved\n##################################################\nEpoch #2\nTraining Loss 1.2033432722091675\nTesting Loss 1.2872092723846436\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #3\nTraining Loss 1.0616378784179688\nTesting Loss 1.3278298377990723\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #4\nTraining Loss 0.9248971343040466\nTesting Loss 1.3802748918533325\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #5\nTraining Loss 0.8202229142189026\nTesting Loss 1.4364666938781738\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #6\nTraining Loss 0.7381296157836914\nTesting Loss 1.4956223964691162\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #7\nTraining Loss 0.6724802851676941\nTesting Loss 1.5539199113845825\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #8\nTraining Loss 0.6209191083908081\nTesting Loss 1.6103041172027588\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #9\nTraining Loss 0.5815939903259277\nTesting Loss 1.666266918182373\n##################################################\n4355/4356 [============================>.] - ETA: 0s  ##################################################\nEpoch #10\nTraining Loss 0.550201952457428\nTesting Loss 1.7127944231033325\n##################################################\n","output_type":"stream"}]},{"cell_type":"code","source":"# create the chatbot function\n# the chatbot function takes in the question as input and answers the input sentence \ndef chatbot(sentence):\n  \n  # clean the input question sentence \n  sentence = clean_text(sentence)\n  # add the start token to the sentence\n  sentence =add_start_end(sentence)\n  # tokenize the sentence\n  inputs = question_tokenizer.texts_to_sequences([sentence])\n  # pad the sentence\n  inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs,\n                                                         maxlen=29,\n                                                         padding='post')\n  \n  # initalize the hidden state of the encoder to zeros\n  hidden = [tf.zeros((1, units))]\n  # pass the sentence to the encoder with the hidden state as the initial hidden state\n  enc_out, enc_hidden = encoder(inputs, hidden)\n  # set the initial decoder hidden state to the encoder hidden state\n  dec_hidden = enc_hidden\n  # create the start token\n  # start_token shape == (batch_size, 1)\n  # repeat the start token for the batch size times\n  dec_input = tf.expand_dims([answer_tokenizer.word_index['<start>']], 0)\n  # create the result string\n  result = ''\n  # loop over the length of the sentence (32)\n\n  for t in range(32):\n    # passing the encoder output and the decoder hidden state to the decoder make sure the decoder input is the previous predicted word\n    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n\n    # getting the predicted word index\n    predicted_id = tf.argmax(predictions[0]).numpy()\n    # getting the predicted word using the predicted index\n    # add the predicted word to the result string \n    result += answer_tokenizer.index_word[predicted_id] + ' '\n    # if the predicted word is the <end> token then stop the loop\n    if answer_tokenizer.index_word[predicted_id] == '<end>':\n      # remove the <start> and <end> tokens from the result string\n      result = result.replace('<start> ', '')\n      result = result.replace(' <end> ','')\n      # remove the <start> and <end> tokens from the sentence string\n      sentence = sentence.replace('<start> ', '')\n      sentence = sentence.replace(' <end>', '')\n      return  sentence, result\n\n    # using the predicted word as the next decoder input\n    dec_input = tf.expand_dims([predicted_id], 0)\n  # remove the <start> and <end> tokens from the result string\n  result = result.replace('<start> ', '')\n  result = result.replace('<end>','')\n  # remove the <start> and <end> tokens from the sentence string\n  sentence = sentence.replace('<start> ', '')\n  sentence = sentence.replace('<end>', '')\n  \n\n  \n \n  \n  # return the result string and the original sentence\n  return sentence, result","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:15.195286Z","iopub.execute_input":"2023-09-23T12:01:15.195930Z","iopub.status.idle":"2023-09-23T12:01:15.207155Z","shell.execute_reply.started":"2023-09-23T12:01:15.195897Z","shell.execute_reply":"2023-09-23T12:01:15.206116Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"chatbot(\"how are you today\")","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:14.774948Z","iopub.execute_input":"2023-09-23T12:01:14.778927Z","iopub.status.idle":"2023-09-23T12:01:14.876632Z","shell.execute_reply.started":"2023-09-23T12:01:14.778898Z","shell.execute_reply":"2023-09-23T12:01:14.875638Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('how are you today', 'i ll be there')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot('what is the weather outside')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:14.877839Z","iopub.execute_input":"2023-09-23T12:01:14.878190Z","iopub.status.idle":"2023-09-23T12:01:14.939633Z","shell.execute_reply.started":"2023-09-23T12:01:14.878150Z","shell.execute_reply":"2023-09-23T12:01:14.938649Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"('what is the weather outside', 'the jewish disease')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot('can you run')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:14.940959Z","iopub.execute_input":"2023-09-23T12:01:14.941276Z","iopub.status.idle":"2023-09-23T12:01:15.046534Z","shell.execute_reply.started":"2023-09-23T12:01:14.941244Z","shell.execute_reply":"2023-09-23T12:01:15.045646Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"('can you run', 'sure i can but that s down')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot(' how old ')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:15.047574Z","iopub.execute_input":"2023-09-23T12:01:15.047935Z","iopub.status.idle":"2023-09-23T12:01:15.120637Z","shell.execute_reply.started":"2023-09-23T12:01:15.047902Z","shell.execute_reply":"2023-09-23T12:01:15.119748Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(' how old ', 'i don t know')"},"metadata":{}}]},{"cell_type":"code","source":"chatbot('can you play')","metadata":{"execution":{"iopub.status.busy":"2023-09-23T12:01:15.122017Z","iopub.execute_input":"2023-09-23T12:01:15.122362Z","iopub.status.idle":"2023-09-23T12:01:15.184859Z","shell.execute_reply.started":"2023-09-23T12:01:15.122329Z","shell.execute_reply":"2023-09-23T12:01:15.183959Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"('can you play', 'oh yes jeffrey')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}